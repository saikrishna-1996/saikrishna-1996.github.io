@incollection{icml2020_6186,
 abstract = {Over the last decade, there has been significant progress in the field of machine learning-based de novo drug discovery, particularly in generative modeling of chemical structures. However, current generative approaches exhibit a significant challenge: they do not ensure the synthetic accessibility nor provide the synthetic routes of the proposed small molecules which limits their applicability. In this work, we propose a novel reinforcement learning (RL) setup for drug discovery that addresses this challenge by embedding the concept of synthetic accessibility directly into the de novo compound design system. In this setup, the agent learns to navigate through the immense synthetically accessible chemical space by subjecting initial commercially available molecules to valid chemical reactions at every time step of the iterative virtual synthesis process. The proposed environment for drug discovery provides a highly challenging test-bed for RL algorithms owing to the large state space and high-dimensional continuous action space with hierarchical actions. Our end-to-end approach achieves state-of-the-art performance when compared against other generative approaches for drug discovery. Moreover, we leverage our approach in a proof-of-concept that mimics the drug discovery process by generating novel HIV drug candidates. Finally, we describe how the end-to-end training conceptualized in this study represents an important paradigm in radically expanding the synthesizable chemical space and automating the drug discovery process.},
 author = {Gottipati, Sai Krishna and Sattarov, Boris and Niu, Sufeng and Wei, Haoran and Pathak, Yashaswi and Liu, Shengchao and Blackburn, Simon and Thomas, Karam and Coley, Connor and Tang, Jian and Chandar, Sarath and Bengio, Yoshua},
 booktitle = {Proceedings of Machine Learning and Systems 2020},
 pages = {10776--10787},
 title = {Learning to Navigate in Synthetically Accessible Chemical Space Using Reinforcement Learning},
 year = {2020}
}

@ARTICLE{8936918,
author={T. {Ort} and K. {Murthy} and R. {Banerjee} and S. K. {Gottipati} and D. {Bhatt}
and I. {Gilitschenski} and L. {Paull} and D. {Rus}},
journal={IEEE Robotics and Automation Letters},
title={MapLite: Autonomous Intersection Navigation Without a Detailed Prior Map},
year={2020},  volume={5},
number={2},  pages={556-563},}


@article{8784238,
author={S. K. {Gottipati} and K. {Seo} and D. {Bhatt} and V. {Mai} and K. {Murthy} and L. {Paull}},
journal={IEEE Robotics and Automation Letters},
title={Deep Active Localization},
year={2019},
volume={4},  number={4},
pages={4394-4401},
}

@INPROCEEDINGS{7989089,
  author={J. K. {Murthy} and G. V. S. {Krishna} and F. {Chhaya} and K. M. {Krishna}},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  title={Reconstructing vehicles from a single image: Shape priors for road scene understanding},
  year={2017},
  volume={},
  number={},
  pages={724-731},}

@article{sai2018deep,
  title={Deep Pepper: Expert Iteration based Chess agent in the Reinforcement Learning Setting},
  author={Sai Krishna G, V and Goyette, Kyle and Chamseddine, Ahmad and Considine, Breandan},
  journal={preprint arXiv:1806.00683},
  year={2018}
}

@article{DBLP:journals/corr/abs-2010-03744,
  author       = {Sai Krishna Gottipati and
                  Yashaswi Pathak and
                  Rohan Nuttall and
                  Sahir and
                  Raviteja Chunduru and
                  Ahmed Touati and
                  Sriram Ganapathi Subramanian and
                  Matthew E. Taylor and
                  Sarath Chandar},
  title        = {Maximum Reward Formulation In Reinforcement Learning},
  journal      = {NeurIPS 2020 Deep RL Workshop},
  volume       = {abs/2010.03744},
  year         = {2020},
  url          = {https://arxiv.org/abs/2010.03744},
  eprinttype    = {arXiv},
  eprint       = {2010.03744},
  timestamp    = {Tue, 13 Oct 2020 15:25:23 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2010-03744.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2106-11345,
  author       = {A. I. Redefined and
                  Sai Krishna Gottipati and
                  Sagar Kurandwad and
                  Clod{\'{e}}ric Mars and
                  Gregory Szriftgiser and
                  Fran{\c{c}}ois Chabot},
  title        = {Cogment: Open Source Framework For Distributed Multi-actor Training,
                  Deployment {\&} Operations},
  journal      = {AAMAS 2022 workshop on Multi-Agent Reinforcement Learning},
  volume       = {abs/2106.11345},
  year         = {2021},
  url          = {https://arxiv.org/abs/2106.11345},
  eprinttype    = {arXiv},
  eprint       = {2106.11345},
  timestamp    = {Wed, 30 Jun 2021 16:14:10 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2106-11345.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}